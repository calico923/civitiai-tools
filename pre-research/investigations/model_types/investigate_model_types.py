#!/usr/bin/env python3
"""
CivitAI APIã®å…¨ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã‚’èª¿æŸ»
"""

import os
import requests
import json
import time
from collections import Counter
from dotenv import load_dotenv

load_dotenv()

class ModelTypeInvestigator:
    def __init__(self):
        self.api_key = os.getenv('CIVITAI_API_KEY')
        self.headers = {
            'User-Agent': 'Mozilla/5.0',
            'Accept': 'application/json',
            'Authorization': f'Bearer {self.api_key}' if self.api_key else None
        }
        self.base_url = 'https://civitai.com/api/v1'
    
    def request(self, endpoint: str, params: dict = None) -> dict:
        """API ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        url = f"{self.base_url}/{endpoint}"
        try:
            response = requests.get(url, headers=self.headers, params=params, timeout=30)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            print(f"Error fetching {endpoint}: {e}")
            return {}
    
    def test_known_types(self) -> dict:
        """æ—¢çŸ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã‚’ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ” æ—¢çŸ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã‚’ãƒ†ã‚¹ãƒˆä¸­...")
        
        # æ—¢çŸ¥ã®ã‚¿ã‚¤ãƒ—ï¼ˆæ§˜ã€…ãªã‚½ãƒ¼ã‚¹ã‹ã‚‰åé›†ï¼‰
        known_types = [
            # åŸºæœ¬ã‚¿ã‚¤ãƒ—
            "Checkpoint", "LORA", "LoCon", "LyCORIS",
            
            # è¿½åŠ ã®å¯èƒ½æ€§ãŒã‚ã‚‹ã‚¿ã‚¤ãƒ—
            "TextualInversion", "Hypernetwork", "AestheticGradient",
            "ControlNet", "VAE", "Embedding", "Poses", "Wildcards",
            "Workflows", "Other", "DoRA", "IP-Adapter", "Motion",
            
            # å¤§æ–‡å­—å°æ–‡å­—ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³
            "checkpoint", "lora", "locon", "lycoris",
            "textualinversion", "hypernetwork", "aestheticgradient",
            "controlnet", "vae", "embedding", "poses", "wildcards",
            "workflows", "other", "dora", "ip-adapter", "motion",
            
            # å¯èƒ½æ€§ã®ã‚ã‚‹æ–°ã—ã„ã‚¿ã‚¤ãƒ—
            "Upscaler", "CLIP", "Model", "Training", "Dataset",
            "Animation", "Video", "Audio", "Style", "Concept"
        ]
        
        results = {}
        
        for model_type in known_types:
            print(f"  Testing type: {model_type}")
            
            response = self.request('models', {
                'types': model_type,
                'limit': 5
            })
            
            if response and 'items' in response:
                items = response['items']
                results[model_type] = {
                    'success': True,
                    'count': len(items),
                    'total_available': response.get('metadata', {}).get('totalItems', 'unknown'),
                    'examples': [item['name'] for item in items[:3]]
                }
                
                if items:
                    print(f"    âœ… Found {len(items)} items (Total: {results[model_type]['total_available']})")
                else:
                    print(f"    âš ï¸ Valid type but no results")
            else:
                results[model_type] = {
                    'success': False,
                    'error': 'Invalid type or API error'
                }
                print(f"    âŒ Invalid or no results")
            
            time.sleep(0.5)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
        
        return results
    
    def discover_types_from_samples(self) -> dict:
        """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å®Ÿéš›ã®ã‚¿ã‚¤ãƒ—ã‚’ç™ºè¦‹"""
        print("\nğŸ”¬ å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‚¿ã‚¤ãƒ—ã‚’åé›†ä¸­...")
        
        # è¤‡æ•°ã®æ¤œç´¢æ¡ä»¶ã§ã‚µãƒ³ãƒ—ãƒ«ã‚’å–å¾—
        search_conditions = [
            {'sort': 'Newest', 'limit': 100},
            {'sort': 'Most Downloaded', 'limit': 100},
            {'sort': 'Highest Rated', 'limit': 100},
            {'baseModels': 'SDXL 1.0', 'limit': 100},
            {'baseModels': 'SD 1.5', 'limit': 100},
            {'baseModels': 'Pony', 'limit': 100},
            {'tags': 'anime', 'limit': 100},
            {'tags': 'realistic', 'limit': 100}
        ]
        
        all_types = []
        
        for i, condition in enumerate(search_conditions, 1):
            print(f"  Sampling condition {i}: {condition}")
            
            response = self.request('models', condition)
            
            if response and 'items' in response:
                for item in response['items']:
                    if 'type' in item:
                        all_types.append(item['type'])
            
            time.sleep(1)
        
        # ã‚¿ã‚¤ãƒ—ã®çµ±è¨ˆ
        type_counts = Counter(all_types)
        
        print(f"\nğŸ“Š ç™ºè¦‹ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ— ({len(type_counts)}ç¨®é¡):")
        for model_type, count in type_counts.most_common():
            print(f"  - {model_type}: {count}å›å‡ºç¾")
        
        return {
            'discovered_types': list(type_counts.keys()),
            'type_statistics': dict(type_counts),
            'total_samples': len(all_types)
        }
    
    def test_multiple_types(self) -> dict:
        """è¤‡æ•°ã‚¿ã‚¤ãƒ—ã®åŒæ™‚æŒ‡å®šã‚’ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ”— è¤‡æ•°ã‚¿ã‚¤ãƒ—ã®åŒæ™‚æŒ‡å®šã‚’ãƒ†ã‚¹ãƒˆä¸­...")
        
        # è¤‡æ•°ã‚¿ã‚¤ãƒ—ã®çµ„ã¿åˆã‚ã›ã‚’ãƒ†ã‚¹ãƒˆ
        multi_type_tests = [
            "Checkpoint,LORA",
            "Checkpoint,LORA,LoCon",
            "LORA,LyCORIS",
            "TextualInversion,Hypernetwork",
            "ControlNet,VAE",
            "Checkpoint|LORA",  # åŒºåˆ‡ã‚Šæ–‡å­—ã®ãƒ†ã‚¹ãƒˆ
            "Checkpoint;LORA",
            "Checkpoint LORA",   # ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Š
        ]
        
        results = {}
        
        for types_param in multi_type_tests:
            print(f"  Testing: {types_param}")
            
            response = self.request('models', {
                'types': types_param,
                'limit': 10
            })
            
            if response and 'items' in response:
                items = response['items']
                found_types = [item['type'] for item in items if 'type' in item]
                unique_types = list(set(found_types))
                
                results[types_param] = {
                    'success': True,
                    'count': len(items),
                    'found_types': unique_types,
                    'type_distribution': dict(Counter(found_types))
                }
                
                print(f"    âœ… Found types: {unique_types}")
            else:
                results[types_param] = {
                    'success': False
                }
                print(f"    âŒ Failed")
            
            time.sleep(0.5)
        
        return results
    
    def investigate_base_model_types(self) -> dict:
        """ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã®èª¿æŸ»"""
        print("\nğŸ—ï¸ ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã‚’èª¿æŸ»ä¸­...")
        
        # ã„ãã¤ã‹ã®ãƒ¢ãƒ‡ãƒ«ã®è©³ç´°ã‚’å–å¾—ã—ã¦baseModelTypeã‚’ç¢ºèª
        sample_model_ids = [140272, 24149, 24350, 25494, 82098]
        
        base_model_types = []
        
        for model_id in sample_model_ids:
            print(f"  Checking model {model_id}...")
            
            response = self.request(f'models/{model_id}')
            
            if response and 'modelVersions' in response:
                for version in response['modelVersions']:
                    if 'baseModelType' in version:
                        base_model_types.append(version['baseModelType'])
            
            time.sleep(1)
        
        base_type_counts = Counter(base_model_types)
        
        print(f"ğŸ“Š ç™ºè¦‹ã—ãŸãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—:")
        for base_type, count in base_type_counts.most_common():
            print(f"  - {base_type}: {count}å›å‡ºç¾")
        
        return {
            'base_model_types': list(base_type_counts.keys()),
            'statistics': dict(base_type_counts)
        }

def main():
    investigator = ModelTypeInvestigator()
    
    print("ğŸ” CivitAI ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã®åŒ…æ‹¬çš„èª¿æŸ»")
    print("=" * 60)
    
    # å„ç¨®èª¿æŸ»ã‚’å®Ÿè¡Œ
    investigations = {
        'known_type_tests': investigator.test_known_types(),
        'discovered_from_samples': investigator.discover_types_from_samples(),
        'multiple_types': investigator.test_multiple_types(),
        'base_model_types': investigator.investigate_base_model_types()
    }
    
    # çµæœã‚’ã¾ã¨ã‚
    print("\n" + "=" * 60)
    print("ğŸ“Š èª¿æŸ»çµæœã‚µãƒãƒªãƒ¼")
    
    # æœ‰åŠ¹ãªã‚¿ã‚¤ãƒ—ã‚’ç‰¹å®š
    valid_types = []
    if 'known_type_tests' in investigations:
        valid_types = [
            type_name for type_name, result in investigations['known_type_tests'].items()
            if result.get('success', False)
        ]
    
    print(f"âœ… æœ‰åŠ¹ãªãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {len(valid_types)}å€‹")
    for type_name in sorted(valid_types):
        result = investigations['known_type_tests'][type_name]
        total = result.get('total_available', 'unknown')
        print(f"  - {type_name}: {total}ãƒ¢ãƒ‡ãƒ«")
    
    # å®Ÿéš›ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‚¿ã‚¤ãƒ—
    if 'discovered_from_samples' in investigations:
        discovered = investigations['discovered_from_samples']['discovered_types']
        print(f"\nğŸ”¬ å®Ÿéš›ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‚¿ã‚¤ãƒ—: {len(discovered)}å€‹")
        for type_name in sorted(discovered):
            count = investigations['discovered_from_samples']['type_statistics'][type_name]
            print(f"  - {type_name}: {count}ã‚µãƒ³ãƒ—ãƒ«")
    
    # è¤‡æ•°ã‚¿ã‚¤ãƒ—æŒ‡å®š
    if 'multiple_types' in investigations:
        working_multi = [
            combo for combo, result in investigations['multiple_types'].items()
            if result.get('success', False)
        ]
        print(f"\nğŸ”— è¤‡æ•°ã‚¿ã‚¤ãƒ—æŒ‡å®š: {len(working_multi)}å€‹ã®çµ„ã¿åˆã‚ã›ãŒå‹•ä½œ")
        for combo in working_multi:
            print(f"  - {combo}")
    
    # çµæœã‚’ä¿å­˜
    with open('model_types_comprehensive_investigation.json', 'w', encoding='utf-8') as f:
        json.dump(investigations, f, indent=2, ensure_ascii=False)
    
    print(f"\nè©³ç´°çµæœ: model_types_comprehensive_investigation.json")

if __name__ == "__main__":
    main()