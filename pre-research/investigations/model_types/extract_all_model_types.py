#!/usr/bin/env python3
"""
æ—¢å­˜ã®èª¿æŸ»çµæœã‹ã‚‰å…¨ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã‚’æŠ½å‡ºãƒ»ã¾ã¨ã‚
"""

import os
import csv
import json
from collections import Counter
from pathlib import Path

def extract_types_from_csv_files():
    """æ—¢å­˜ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰model_typeã‚’æŠ½å‡º"""
    model_types = []
    
    # outputsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ã™ã¹ã¦ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    outputs_dir = Path('/Users/kuniaki-k/Code/civitiai/outputs')
    
    csv_files = list(outputs_dir.rglob('*.csv'))
    
    print(f"ğŸ” {len(csv_files)}å€‹ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ä¸­...")
    
    for csv_file in csv_files:
        try:
            with open(csv_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                
                # model_typeã‚«ãƒ©ãƒ ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                if 'model_type' in reader.fieldnames:
                    for row in reader:
                        model_type = row.get('model_type', '').strip()
                        if model_type and model_type != 'model_type':
                            model_types.append(model_type)
                            
        except Exception as e:
            print(f"  Error reading {csv_file}: {e}")
    
    return model_types

def extract_types_from_enhanced_data():
    """enhancedãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰è©³ç´°ãªã‚¿ã‚¤ãƒ—æƒ…å ±ã‚’æŠ½å‡º"""
    enhanced_dir = Path('/Users/kuniaki-k/Code/civitiai/outputs/enhanced/old/detailed_search_data')
    
    model_types = []
    
    if enhanced_dir.exists():
        # illustrious_checkpoint, illustrious_lora, illustrious_lycoris ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºèª
        type_dirs = ['illustrious_checkpoint', 'illustrious_lora', 'illustrious_lycoris']
        
        for type_dir in type_dirs:
            dir_path = enhanced_dir / type_dir
            if dir_path.exists():
                # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã‹ã‚‰ã‚¿ã‚¤ãƒ—ã‚’æ¨æ¸¬
                if 'checkpoint' in type_dir:
                    model_types.append('Checkpoint')
                elif 'lora' in type_dir:
                    model_types.append('LORA')
                elif 'lycoris' in type_dir:
                    model_types.append('LoCon')  # LyCORISã¯APIã§ã¯LoConã¨ã—ã¦å‡¦ç†
                
                # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ãƒã‚§ãƒƒã‚¯
                for csv_file in dir_path.glob('*.csv'):
                    try:
                        with open(csv_file, 'r', encoding='utf-8') as f:
                            reader = csv.DictReader(f)
                            if 'model_type' in reader.fieldnames:
                                for row in reader:
                                    model_type = row.get('model_type', '').strip()
                                    if model_type:
                                        model_types.append(model_type)
                    except:
                        pass
    
    return model_types

def compile_comprehensive_types():
    """åŒ…æ‹¬çš„ãªãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ãƒªã‚¹ãƒˆã‚’ä½œæˆ"""
    
    print("ğŸ“Š æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã‚’æŠ½å‡ºä¸­...")
    
    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æŠ½å‡º
    csv_types = extract_types_from_csv_files()
    print(f"  CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰: {len(csv_types)}å€‹ã®ã‚¿ã‚¤ãƒ—ã‚¨ãƒ³ãƒˆãƒª")
    
    # Enhanced ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æŠ½å‡º
    enhanced_types = extract_types_from_enhanced_data()
    print(f"  Enhancedãƒ‡ãƒ¼ã‚¿ã‹ã‚‰: {len(enhanced_types)}å€‹ã®ã‚¿ã‚¤ãƒ—ã‚¨ãƒ³ãƒˆãƒª")
    
    # ã™ã¹ã¦çµ±åˆ
    all_types = csv_types + enhanced_types
    
    # çµ±è¨ˆä½œæˆ
    type_counts = Counter(all_types)
    
    print(f"\nğŸ“‹ ç™ºè¦‹ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ— ({len(type_counts)}ç¨®é¡):")
    for model_type, count in type_counts.most_common():
        print(f"  - {model_type}: {count}å›å‡ºç¾")
    
    # å…¬å¼ãƒ†ã‚¹ãƒˆçµæœã¨ã®çµ±åˆ
    tested_types = [
        "Checkpoint", "LORA", "LoCon", "TextualInversion", 
        "Hypernetwork", "AestheticGradient", "VAE", 
        "Poses", "Wildcards", "Other"
    ]
    
    # ç™ºè¦‹ã•ã‚ŒãŸã‚¿ã‚¤ãƒ—ã¨å…¬å¼ãƒ†ã‚¹ãƒˆçµæœã‚’çµ±åˆ
    all_discovered = list(type_counts.keys())
    all_valid_types = list(set(all_discovered + tested_types))
    
    # çµæœã‚’ã¾ã¨ã‚
    results = {
        'discovered_from_data': dict(type_counts),
        'confirmed_via_api_test': tested_types,
        'all_valid_types': sorted(all_valid_types),
        'statistics': {
            'total_entries_analyzed': len(all_types),
            'unique_types_found': len(type_counts),
            'most_common_type': type_counts.most_common(1)[0] if type_counts else None
        }
    }
    
    return results

def create_comprehensive_documentation():
    """åŒ…æ‹¬çš„ãªãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆ"""
    
    results = compile_comprehensive_types()
    
    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆ
    doc = """# CivitAI API Model Types å®Œå…¨ãƒªã‚¹ãƒˆ

## ğŸ“‹ æ¦‚è¦
CivitAI APIã®`types`ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§åˆ©ç”¨å¯èƒ½ãªã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã®å®Œå…¨ãƒªã‚¹ãƒˆ

## âœ… ç¢ºèªæ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—

### ä¸»è¦ã‚¿ã‚¤ãƒ—ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ã§ç¢ºèªï¼‰
"""
    
    # å®Ÿãƒ‡ãƒ¼ã‚¿ã§ç¢ºèªã•ã‚ŒãŸã‚¿ã‚¤ãƒ—
    discovered = results['discovered_from_data']
    for model_type, count in sorted(discovered.items(), key=lambda x: x[1], reverse=True):
        doc += f"- **`{model_type}`** - {count:,}å€‹ã®ãƒ¢ãƒ‡ãƒ«ã§ç¢ºèª\n"
    
    doc += "\n### APIãƒ†ã‚¹ãƒˆã§ç¢ºèªã•ã‚ŒãŸã‚¿ã‚¤ãƒ—\n"
    
    # APIãƒ†ã‚¹ãƒˆã§ç¢ºèªã•ã‚ŒãŸã‚¿ã‚¤ãƒ—
    for model_type in sorted(results['confirmed_via_api_test']):
        if model_type not in discovered:
            doc += f"- **`{model_type}`** - APIãƒ†ã‚¹ãƒˆã§å‹•ä½œç¢ºèªæ¸ˆã¿\n"
    
    doc += f"""

## ğŸ” ä½¿ç”¨ä¾‹

### å˜ä¸€ã‚¿ã‚¤ãƒ—æŒ‡å®š
```python
# Checkpointã®ã¿æ¤œç´¢
models = client.search_models(types='Checkpoint')

# LoRAã®ã¿æ¤œç´¢  
loras = client.search_models(types='LORA')

# TextualInversionã®ã¿æ¤œç´¢
textual_inversions = client.search_models(types='TextualInversion')
```

### è¤‡æ•°ã‚¿ã‚¤ãƒ—æŒ‡å®š
```python
# Checkpointã¨LoRAã‚’åŒæ™‚æ¤œç´¢
models = client.search_models(types='Checkpoint,LORA')

# 3ã¤ã®ã‚¿ã‚¤ãƒ—ã‚’åŒæ™‚æ¤œç´¢
models = client.search_models(types='Checkpoint,LORA,LoCon')
```

## ğŸ“Š çµ±è¨ˆæƒ…å ±

- **ç·åˆ†æã‚¨ãƒ³ãƒˆãƒªæ•°**: {results['statistics']['total_entries_analyzed']:,}
- **ç™ºè¦‹ã•ã‚ŒãŸãƒ¦ãƒ‹ãƒ¼ã‚¯ã‚¿ã‚¤ãƒ—æ•°**: {results['statistics']['unique_types_found']}
- **æœ€å¤šå‡ºç¾ã‚¿ã‚¤ãƒ—**: {results['statistics']['most_common_type'][0] if results['statistics']['most_common_type'] else 'N/A'}

## ğŸ¯ é‡è¦ãªæ³¨æ„ç‚¹

### LyCORIS vs LoCon
- **LyCORIS**: ä¸€èˆ¬çš„ãªåç§°
- **LoCon**: CivitAI APIã§ã®å†…éƒ¨è¡¨ç¾
- APIã§ã¯ `types='LoCon'` ã‚’ä½¿ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚‹

### å¤§æ–‡å­—å°æ–‡å­—
- ã‚¿ã‚¤ãƒ—åã¯å¤§æ–‡å­—å°æ–‡å­—ãŒåŒºåˆ¥ã•ã‚Œã‚‹
- æ­£ç¢ºãªè¡¨è¨˜ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ï¼ˆä¾‹ï¼š`Checkpoint`ã€`LORA`ï¼‰

### åŒºåˆ‡ã‚Šæ–‡å­—
- è¤‡æ•°ã‚¿ã‚¤ãƒ—æŒ‡å®šæ™‚ã¯ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š: `'Checkpoint,LORA'`
- ã‚¹ãƒšãƒ¼ã‚¹ã¯å«ã‚ãªã„

## ğŸ“ æ›´æ–°å±¥æ­´
- åˆç‰ˆä½œæˆ: å®Ÿè¨¼çš„èª¿æŸ»ã«ã‚ˆã‚Šå…¨ã‚¿ã‚¤ãƒ—ã‚’ç‰¹å®š
- ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: {results['statistics']['total_entries_analyzed']:,}å€‹ã®ãƒ¢ãƒ‡ãƒ«ã‚¨ãƒ³ãƒˆãƒªã‚’åˆ†æ
"""
    
    return doc, results

def main():
    print("ğŸ” CivitAI Model Types å®Œå…¨èª¿æŸ»")
    print("=" * 50)
    
    # åŒ…æ‹¬çš„èª¿æŸ»å®Ÿè¡Œ
    documentation, results = create_comprehensive_documentation()
    
    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¿å­˜
    with open('docs/civitai_model_types_complete.md', 'w', encoding='utf-8') as f:
        f.write(documentation)
    
    # çµæœãƒ‡ãƒ¼ã‚¿ä¿å­˜
    with open('model_types_complete_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print("\nğŸ¯ å®Œå…¨ãªãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ãƒªã‚¹ãƒˆ:")
    for model_type in sorted(results['all_valid_types']):
        status = ""
        if model_type in results['discovered_from_data']:
            count = results['discovered_from_data'][model_type]
            status = f"({count:,}å€‹ã§ç¢ºèª)"
        elif model_type in results['confirmed_via_api_test']:
            status = "(APIãƒ†ã‚¹ãƒˆæ¸ˆã¿)"
        
        print(f"  âœ… {model_type} {status}")
    
    print(f"\nğŸ“š ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ: docs/civitai_model_types_complete.md")
    print(f"ğŸ“Š è©³ç´°ãƒ‡ãƒ¼ã‚¿: model_types_complete_analysis.json")

if __name__ == "__main__":
    main()