#!/usr/bin/env python3
"""
CivitAI API Model Types ã®æœ€çµ‚çš„ãªåŒ…æ‹¬èª¿æŸ»çµæœ
"""

import json
from datetime import datetime

def create_final_documentation():
    """æœ€çµ‚çš„ãªåŒ…æ‹¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆ"""
    
    # å…¨èª¿æŸ»çµæœã‚’çµ±åˆ
    final_results = {
        # APIãƒ†ã‚¹ãƒˆã§ç¢ºèªæ¸ˆã¿ã®åŸºæœ¬ã‚¿ã‚¤ãƒ—
        "confirmed_basic_types": [
            "Checkpoint", "LORA", "LoCon", "TextualInversion", 
            "Hypernetwork", "AestheticGradient", "VAE", 
            "Poses", "Wildcards", "Other"
        ],
        
        # æ–°ç™ºè¦‹ã®ã‚¿ã‚¤ãƒ—
        "newly_discovered_types": [
            "DoRA", "Workflows", "Upscaler"
        ],
        
        # å…¬å¼æ•™è‚²è¨˜äº‹ã§è¨€åŠã•ã‚Œã¦ã„ã‚‹ã‚¿ã‚¤ãƒ—
        "officially_mentioned_types": [
            "Checkpoint", "LORA", "LyCORIS", "Embedding", "VAE", "Workflows", "Wildcards"
        ],
        
        # APIã§ç„¡åŠ¹/åˆ©ç”¨ä¸å¯
        "invalid_types": [
            "Embedding", "Embeddings", "Tool", "Tools", "ControlNet", 
            "Motion", "Video", "Audio", "IP-Adapter", "T2I-Adapter"
        ],
        
        # å®Ÿãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ
        "data_statistics": {
            "LORA": 21220,
            "Checkpoint": 11694,
            "LoCon": 6029
        }
    }
    
    # å…¨æœ‰åŠ¹ã‚¿ã‚¤ãƒ—ãƒªã‚¹ãƒˆï¼ˆé‡è¤‡é™¤å»ï¼‰
    all_valid = set()
    all_valid.update(final_results["confirmed_basic_types"])
    all_valid.update(final_results["newly_discovered_types"])
    
    final_valid_types = sorted(list(all_valid))
    
    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆ
    doc = f"""# CivitAI API Model Types æœ€çµ‚å®Œå…¨ãƒªã‚¹ãƒˆ

## ğŸ“‹ æ¦‚è¦
CivitAI APIã®`types`ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§åˆ©ç”¨å¯èƒ½ãª**å…¨ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã®æ±ºå®šç‰ˆãƒªã‚¹ãƒˆ**

**èª¿æŸ»æ—¥æ™‚**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}
**èª¿æŸ»æ–¹æ³•**: APIãƒ†ã‚¹ãƒˆ + å®Ÿãƒ‡ãƒ¼ã‚¿åˆ†æ + å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç¢ºèª

---

## âœ… ç¢ºèªæ¸ˆã¿æœ‰åŠ¹ã‚¿ã‚¤ãƒ— ({len(final_valid_types)}ç¨®é¡)

### ğŸ† ä¸»è¦ã‚¿ã‚¤ãƒ—ï¼ˆå¤§é‡ãƒ‡ãƒ¼ã‚¿ã§ç¢ºèªï¼‰
"""
    
    for type_name in ["LORA", "Checkpoint", "LoCon"]:
        count = final_results["data_statistics"].get(type_name, 0)
        doc += f"- **`{type_name}`** - {count:,}å€‹ã®ãƒ¢ãƒ‡ãƒ«ã§ç¢ºèªæ¸ˆã¿\n"
    
    doc += "\n### ğŸ”¬ APIãƒ†ã‚¹ãƒˆç¢ºèªæ¸ˆã¿\n"
    for type_name in final_results["confirmed_basic_types"]:
        if type_name not in final_results["data_statistics"]:
            doc += f"- **`{type_name}`** - APIãƒ†ã‚¹ãƒˆã§å‹•ä½œç¢ºèª\n"
    
    doc += "\n### ğŸ†• æ–°ç™ºè¦‹ã‚¿ã‚¤ãƒ—\n"
    for type_name in final_results["newly_discovered_types"]:
        doc += f"- **`{type_name}`** - ä»Šå›ã®èª¿æŸ»ã§æ–°ç™ºè¦‹\n"
    
    doc += f"""

## ğŸš« ç„¡åŠ¹ãªã‚¿ã‚¤ãƒ—

ä»¥ä¸‹ã®ã‚¿ã‚¤ãƒ—ã¯APIã§**HTTP 400ã‚¨ãƒ©ãƒ¼**ã¨ãªã‚Šä½¿ç”¨ä¸å¯:
"""
    
    for type_name in final_results["invalid_types"][:10]:  # æœ€åˆã®10å€‹
        doc += f"- `{type_name}`\n"
    
    doc += f"""
... ä»– {len(final_results['invalid_types']) - 10}å€‹

## ğŸ” ä½¿ç”¨ä¾‹

### åŸºæœ¬çš„ãªä½¿ç”¨
```python
# ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¤ãƒ—
checkpoints = client.search_models(types='Checkpoint')
loras = client.search_models(types='LORA')
embeddings = client.search_models(types='TextualInversion')

# æ–°ç™ºè¦‹ã‚¿ã‚¤ãƒ—
upscalers = client.search_models(types='Upscaler')
workflows = client.search_models(types='Workflows')
dora_models = client.search_models(types='DoRA')
```

### è¤‡æ•°ã‚¿ã‚¤ãƒ—æ¤œç´¢
```python
# å­¦ç¿’ç´ æã¨ã—ã¦ä½¿ãˆã‚‹å…¨ã‚¿ã‚¤ãƒ—
training_materials = client.search_models(
    types='Checkpoint,LORA,LoCon,DoRA'
)

# å¾Œå‡¦ç†ç”¨ãƒ„ãƒ¼ãƒ«
post_processing = client.search_models(
    types='VAE,Upscaler'
)

# ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é–¢é€£
workflow_resources = client.search_models(
    types='Workflows,Wildcards'
)
```

## âš ï¸ é‡è¦ãªæ³¨æ„äº‹é …

### LyCORIS vs LoCon
- **ä¸€èˆ¬çš„åç§°**: LyCORIS
- **APIå†…éƒ¨å**: LoCon
- **ä½¿ç”¨æ™‚**: `types='LoCon'` ã‚’æŒ‡å®š

### TextualInversion vs Embedding
- **APIå**: TextualInversion
- **ä¸€èˆ¬å**: Embedding, Textual Inversion
- **ä½¿ç”¨æ™‚**: `types='TextualInversion'` ã‚’æŒ‡å®š

### å¤§æ–‡å­—å°æ–‡å­—ã®é‡è¦æ€§
- ã™ã¹ã¦**å¤§æ–‡å­—å°æ–‡å­—ã‚’æ­£ç¢º**ã«æŒ‡å®šã™ã‚‹å¿…è¦ã‚ã‚Š
- é–“é•ã„ä¾‹: `checkpoint`, `lora`, `embedding`
- æ­£ã—ã„ä¾‹: `Checkpoint`, `LORA`, `TextualInversion`

## ğŸ“Š çµ±è¨ˆãƒ‡ãƒ¼ã‚¿

### èª¿æŸ»è¦æ¨¡
- **åˆ†æã—ãŸãƒ¢ãƒ‡ãƒ«æ•°**: {sum(final_results['data_statistics'].values()):,}å€‹
- **ãƒ†ã‚¹ãƒˆã—ãŸã‚¿ã‚¤ãƒ—æ•°**: 70+å€‹
- **ç¢ºèªæ¸ˆã¿æœ‰åŠ¹ã‚¿ã‚¤ãƒ—**: {len(final_valid_types)}å€‹

### ã‚¿ã‚¤ãƒ—åˆ¥åˆ†å¸ƒ
"""
    
    for type_name, count in sorted(final_results["data_statistics"].items(), key=lambda x: x[1], reverse=True):
        percentage = count / sum(final_results["data_statistics"].values()) * 100
        doc += f"- **{type_name}**: {count:,}å€‹ ({percentage:.1f}%)\n"
    
    doc += f"""

## ğŸ”„ ä»Šå¾Œã®å±•é–‹

### æ–°ã—ã„ã‚¿ã‚¤ãƒ—ã®å¯èƒ½æ€§
- AIæŠ€è¡“ã®é€²æ­©ã«ã‚ˆã‚Šæ–°ã—ã„ã‚¿ã‚¤ãƒ—ãŒè¿½åŠ ã•ã‚Œã‚‹å¯èƒ½æ€§
- **Motion**, **ControlNet**, **IP-Adapter** ç­‰ã¯å°†æ¥å®Ÿè£…ã®å¯èƒ½æ€§

### å®šæœŸãƒã‚§ãƒƒã‚¯æ¨å¥¨
- æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã®å®šæœŸçš„ãªç¢ºèª
- CivitAIå…¬å¼ã‚¢ãƒŠã‚¦ãƒ³ã‚¹ã®ãƒ•ã‚©ãƒ­ãƒ¼

## ğŸ“š å‚è€ƒè³‡æ–™

- **CivitAIå…¬å¼ã‚¬ã‚¤ãƒ‰**: https://education.civitai.com/civitais-guide-to-resource-types/
- **APIä»•æ§˜**: https://developer.civitai.com/docs/api/public-rest
- **å®Ÿè¨¼èª¿æŸ»ãƒ‡ãƒ¼ã‚¿**: 38,943å€‹ã®ãƒ¢ãƒ‡ãƒ«ã‚¨ãƒ³ãƒˆãƒªã‚’åˆ†æ

---

## ğŸ“ å®Œå…¨ãªã‚¿ã‚¤ãƒ—ãƒªã‚¹ãƒˆ

"""
    
    for i, type_name in enumerate(final_valid_types, 1):
        doc += f"{i:2d}. **`{type_name}`**\n"
    
    doc += f"""

**åˆè¨ˆ: {len(final_valid_types)}ç¨®é¡ã®æœ‰åŠ¹ãªãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—**

> ã“ã®ä¸€è¦§ã¯å®Ÿè¨¼çš„èª¿æŸ»ã«åŸºã¥ãæ±ºå®šç‰ˆã§ã™ã€‚
> æ–°ã—ã„ã‚¿ã‚¤ãƒ—ãŒè¿½åŠ ã•ã‚ŒãŸå ´åˆã¯ã€ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ›´æ–°ã—ã¦ãã ã•ã„ã€‚
"""
    
    return doc, final_valid_types

def main():
    print("ğŸ“š CivitAI Model Types æœ€çµ‚åŒ…æ‹¬èª¿æŸ»")
    print("=" * 50)
    
    documentation, final_types = create_final_documentation()
    
    # æœ€çµ‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¿å­˜
    with open('docs/civitai_model_types_final_complete.md', 'w', encoding='utf-8') as f:
        f.write(documentation)
    
    # æœ€çµ‚çµæœãƒ‡ãƒ¼ã‚¿ä¿å­˜
    final_data = {
        'final_valid_types': final_types,
        'total_count': len(final_types),
        'investigation_date': datetime.now().isoformat(),
        'data_sources': [
            'API endpoint testing',
            'Real model data analysis (38,943 entries)',
            'Official documentation review'
        ]
    }
    
    with open('civitai_model_types_final_results.json', 'w', encoding='utf-8') as f:
        json.dump(final_data, f, indent=2, ensure_ascii=False)
    
    print("ğŸ¯ æœ€çµ‚çµæœ:")
    print(f"  âœ… æœ‰åŠ¹ãªãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {len(final_types)}ç¨®é¡")
    print(f"  ğŸ“Š åˆ†æãƒ‡ãƒ¼ã‚¿: 38,943å€‹ã®ãƒ¢ãƒ‡ãƒ«")
    print(f"  ğŸ”¬ ãƒ†ã‚¹ãƒˆæ¸ˆã¿ã‚¿ã‚¤ãƒ—: 70+å€‹")
    
    print(f"\nğŸ“‹ å®Œå…¨ãªã‚¿ã‚¤ãƒ—ãƒªã‚¹ãƒˆ:")
    for i, type_name in enumerate(final_types, 1):
        print(f"  {i:2d}. {type_name}")
    
    print(f"\nğŸ“š ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: docs/civitai_model_types_final_complete.md")
    print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«: civitai_model_types_final_results.json")

if __name__ == "__main__":
    main()