#!/usr/bin/env python3
"""
è¤‡æ•°ã®CivitAI URLã‹ã‚‰ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’ä¸€æ‹¬å–å¾—ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Example usage:
    python batch_url_collector.py urls.txt
    python batch_url_collector.py urls.txt --export-html
"""

import os
import sys
import argparse
from pathlib import Path
from datetime import datetime
from typing import List

# Add src to path
sys.path.append(str(Path(__file__).parent.parent.parent))

from src.api.client import CivitaiClient
from src.core.enhanced_url_collector import EnhancedURLCollector


def collect_models_from_urls(urls_file: str, 
                           api_key: str, 
                           validate_urls: bool = False,
                           export_html: bool = False,
                           output_dir: str = "outputs/enhanced") -> None:
    """
    URLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’ä¸€æ‹¬å–å¾—
    
    Args:
        urls_file: URLä¸€è¦§ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ1è¡Œã«1URLï¼‰
        api_key: CivitAI APIã‚­ãƒ¼
        validate_urls: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URLæ¤œè¨¼ã®æœ‰ç„¡
        export_html: HTMLå½¢å¼ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã®æœ‰ç„¡
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    """
    print(f"ğŸ” URLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’ä¸€æ‹¬å–å¾—: {urls_file}")
    
    # URLãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    try:
        with open(urls_file, 'r', encoding='utf-8') as f:
            urls = [line.strip() for line in f if line.strip() and not line.startswith('#')]
    except FileNotFoundError:
        print(f"âŒ URLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {urls_file}")
        sys.exit(1)
    
    if not urls:
        print("âŒ æœ‰åŠ¹ãªURLãŒãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚ã‚Šã¾ã›ã‚“")
        sys.exit(1)
    
    print(f"ğŸ“‹ {len(urls)}å€‹ã®URLã‚’æ¤œå‡º")
    
    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
    client = CivitaiClient(api_key)
    enhanced_collector = EnhancedURLCollector(api_key=api_key)
    enhanced_collector.output_dir = Path(output_dir)
    enhanced_collector.output_dir.mkdir(parents=True, exist_ok=True)
    
    # ãƒ¢ãƒ‡ãƒ«æƒ…å ±åé›†
    all_model_data = []
    successful_count = 0
    failed_count = 0
    
    for i, url in enumerate(urls, 1):
        print(f"\nğŸ“ˆ é€²è¡ŒçŠ¶æ³: {i}/{len(urls)} - {url}")
        
        try:
            model_data = client.get_model_from_url(url)
            all_model_data.append(model_data)
            successful_count += 1
            
            print(f"âœ… æˆåŠŸ: {model_data.get('name', 'Unknown')} (ID: {model_data.get('id')})")
            
        except Exception as e:
            failed_count += 1
            print(f"âŒ å¤±æ•—: {e}")
            continue
    
    print(f"\nğŸ“Š å–å¾—çµæœ: æˆåŠŸ {successful_count}å€‹, å¤±æ•— {failed_count}å€‹")
    
    if not all_model_data:
        print("âŒ å–å¾—ã§ããŸãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # æ‹¡å¼µæƒ…å ±ã«å¤‰æ›
    print("\nğŸ”„ æ‹¡å¼µãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’ç”Ÿæˆä¸­...")
    model_infos = enhanced_collector.collect_enhanced_model_info(all_model_data)
    
    if validate_urls:
        print("ğŸ” ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URLæ¤œè¨¼ä¸­...")
        model_infos = enhanced_collector.validate_download_urls(model_infos)
    
    if model_infos:
        # ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        base_filename = f"batch_url_collection_{timestamp}"
        
        # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        print("\nğŸ“ çµæœã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­...")
        exported_files = enhanced_collector.export_all_formats(model_infos, base_filename)
        
        print(f"ğŸ“Š CSV: {exported_files['csv']}")
        print(f"ğŸ“‹ JSON: {exported_files['json']}")
        
        if export_html:
            print(f"ğŸŒ HTML: {exported_files['html']}")
        
        # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
        print(f"\nâœ… ä¸€æ‹¬å–å¾—å®Œäº†!")
        print(f"ğŸ“Š ç·ãƒ¢ãƒ‡ãƒ«æ•°: {len(model_infos)}")
        print(f"ğŸ‘¥ ä½œæˆè€…: {len(set(info.creator for info in model_infos))}äºº")
        print(f"ğŸ·ï¸ ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {', '.join(set(info.model_type for info in model_infos))}")
        
        # ãƒˆãƒƒãƒ—ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ¢ãƒ‡ãƒ«
        top_downloads = sorted(model_infos, key=lambda x: x.download_count or 0, reverse=True)[:3]
        print(f"\nğŸ”¥ ãƒˆãƒƒãƒ—ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰:")
        for i, model in enumerate(top_downloads, 1):
            print(f"   {i}. {model.model_name} - {model.download_count}ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description="CivitAI URLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’ä¸€æ‹¬å–å¾—"
    )
    
    parser.add_argument(
        "urls_file",
        help="URLä¸€è¦§ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ1è¡Œã«1URLã€#ã§å§‹ã¾ã‚‹è¡Œã¯ã‚³ãƒ¡ãƒ³ãƒˆï¼‰"
    )
    parser.add_argument(
        "--validate-urls",
        action="store_true",
        help="ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URLã®æ¤œè¨¼ã‚’å®Ÿè¡Œ"
    )
    parser.add_argument(
        "--export-html",
        action="store_true",
        help="HTMLå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"
    )
    parser.add_argument(
        "--output-dir",
        default="outputs/enhanced",
        help="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (default: outputs/enhanced)"
    )
    
    args = parser.parse_args()
    
    # API ã‚­ãƒ¼å–å¾—
    api_key = os.getenv("CIVITAI_API_KEY")
    if not api_key:
        print("âŒ ã‚¨ãƒ©ãƒ¼: CIVITAI_API_KEYç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        sys.exit(1)
    
    # ä¸€æ‹¬å–å¾—å®Ÿè¡Œ
    collect_models_from_urls(
        urls_file=args.urls_file,
        api_key=api_key,
        validate_urls=args.validate_urls,
        export_html=args.export_html,
        output_dir=args.output_dir
    )


if __name__ == "__main__":
    main()