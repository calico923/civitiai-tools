#!/usr/bin/env python3
"""2ã¤ã®æ¤œç´¢æ–¹æ³•ã‚’çµ±åˆã—ã¦ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’å®Œå…¨å–å¾—"""

import os
import sys
from pathlib import Path
from typing import List, Dict, Set

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv
from src.api.client import CivitaiClient
from src.core.url_collector import URLCollector


def collect_complete_checkpoints(client: CivitaiClient, base_model: str, max_pages_direct: int = 5, max_pages_base: int = 30) -> List[Dict]:
    """2ã¤ã®æ–¹æ³•ã§ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’å®Œå…¨å–å¾—"""
    
    all_models = []
    seen_ids = set()  # é‡è¤‡é™¤å»ç”¨
    
    print(f"\n{'='*60}")
    print(f"ğŸ” {base_model.upper()} ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå®Œå…¨å–å¾—")
    print(f"{'='*60}")
    
    # æ–¹æ³•1: ç›´æ¥ã‚¿ã‚°æ¤œç´¢
    print(f"1. {base_model}ã‚¿ã‚°ã§ç›´æ¥æ¤œç´¢ä¸­...")
    try:
        direct_models = client.search_models_with_cursor(
            types=["Checkpoint"],
            tag=base_model,
            sort="Most Downloaded",
            limit=100,
            max_pages=max_pages_direct
        )
        
        print(f"   ç›´æ¥ã‚¿ã‚°æ¤œç´¢çµæœ: {len(direct_models)}å€‹")
        
        # é‡è¤‡é™¤å»ã—ãªãŒã‚‰è¿½åŠ 
        for model in direct_models:
            model_id = model.get('id')
            if model_id and model_id not in seen_ids:
                all_models.append(model)
                seen_ids.add(model_id)
        
        print(f"   è¿½åŠ æ¸ˆã¿: {len(all_models)}å€‹")
        
    except Exception as e:
        print(f"   ç›´æ¥ã‚¿ã‚°æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
    
    # æ–¹æ³•2: base modelã‚¿ã‚°ã‹ã‚‰æ¤œç´¢ã—ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    print(f"\n2. base modelã‚¿ã‚°ã‹ã‚‰{base_model}æ¤œç´¢ä¸­...")
    try:
        base_model_checkpoints = client.search_models_with_cursor(
            types=["Checkpoint"],
            tag="base model",
            sort="Most Downloaded",
            limit=100,
            max_pages=max_pages_base
        )
        
        print(f"   base modelç·å–å¾—æ•°: {len(base_model_checkpoints)}å€‹")
        
        # base_modelã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        filtered_models = []
        base_model_lower = base_model.lower()
        
        for model in base_model_checkpoints:
            name = model.get('name', '').lower()
            tags = [tag.lower() for tag in model.get('tags', [])]
            description = model.get('description', '').lower()
            
            if (base_model_lower in name or 
                base_model_lower in tags or 
                base_model_lower in description):
                filtered_models.append(model)
        
        print(f"   {base_model}é–¢é€£ãƒ•ã‚£ãƒ«ã‚¿çµæœ: {len(filtered_models)}å€‹")
        
        # é‡è¤‡é™¤å»ã—ãªãŒã‚‰è¿½åŠ 
        added_count = 0
        for model in filtered_models:
            model_id = model.get('id')
            if model_id and model_id not in seen_ids:
                all_models.append(model)
                seen_ids.add(model_id)
                added_count += 1
        
        print(f"   æ–°è¦è¿½åŠ : {added_count}å€‹")
        
    except Exception as e:
        print(f"   base modelæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
    
    print(f"\nâœ… {base_model.upper()}å®Œå…¨å–å¾—çµæœ: {len(all_models)}å€‹")
    return all_models


def main():
    print("=== ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå®Œå…¨å–å¾— ===")
    print("2ã¤ã®æ¤œç´¢æ–¹æ³•ã‚’çµ±åˆã—ã¦Webãƒšãƒ¼ã‚¸ã¨åŒç­‰ã®çµæœã‚’å–å¾—")
    
    # ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
    load_dotenv()
    api_key = os.getenv('CIVITAI_API_KEY')
    
    if not api_key:
        print("ã‚¨ãƒ©ãƒ¼: CIVITAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return
    
    try:
        # APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
        print("\n1. Civitai APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–ä¸­...")
        client = CivitaiClient(api_key)
        collector = URLCollector()
        
        # å¯¾è±¡ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«
        base_models = ['pony', 'illustrious', 'noobai']
        all_results = {}
        
        # å„ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®å®Œå…¨å–å¾—
        for base_model in base_models:
            complete_models = collect_complete_checkpoints(
                client, 
                base_model, 
                max_pages_direct=5,   # ç›´æ¥ã‚¿ã‚°æ¤œç´¢: æœ€å¤§500å€‹
                max_pages_base=30     # base modelæ¤œç´¢: æœ€å¤§3000å€‹
            )
            
            if complete_models:
                # URLåé›†
                urls = collector.collect_model_urls(complete_models)
                print(f"   ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URL: {len(urls)}å€‹")
                
                # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
                filename_base = f"{base_model}_checkpoints_complete"
                
                csv_file = collector.export_to_csv(urls, f"{filename_base}.csv")
                json_file = collector.export_to_json(urls, f"{filename_base}.json")
                text_file = collector.export_to_text(urls, f"{filename_base}.txt")
                
                print(f"   ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›:")
                print(f"     CSV:  {csv_file}")
                print(f"     JSON: {json_file}")
                print(f"     TXT:  {text_file}")
                
                # çµæœä¿å­˜
                all_results[base_model] = {
                    'models': complete_models,
                    'urls': urls,
                    'count': len(complete_models)
                }
                
                # ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
                print(f"   ğŸ“Š {base_model.upper()}ã‚µãƒ³ãƒ—ãƒ«ï¼ˆä¸Šä½5å€‹ï¼‰:")
                for i, model in enumerate(complete_models[:5], 1):
                    name = model.get('name', 'Unknown')
                    tags = ', '.join(model.get('tags', [])[:3])
                    print(f"     {i}. {name}")
                    print(f"        ã‚¿ã‚°: {tags}")
            else:
                print(f"   âŒ {base_model}ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                all_results[base_model] = {'models': [], 'urls': [], 'count': 0}
        
        # çµ±åˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        print(f"\n{'='*60}")
        print(f"ğŸ“„ çµ±åˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆä¸­...")
        print(f"{'='*60}")
        
        all_urls = []
        for result in all_results.values():
            all_urls.extend(result['urls'])
        
        if all_urls:
            # é‡è¤‡é™¤å»ï¼ˆURLãƒ™ãƒ¼ã‚¹ï¼‰
            seen_urls = set()
            unique_urls = []
            for url_info in all_urls:
                url = url_info.download_url
                if url not in seen_urls:
                    unique_urls.append(url_info)
                    seen_urls.add(url)
            
            print(f"çµ±åˆå‰: {len(all_urls)}å€‹")
            print(f"é‡è¤‡é™¤å»å¾Œ: {len(unique_urls)}å€‹")
            
            unified_csv = collector.export_to_csv(unique_urls, "all_base_model_checkpoints_complete.csv")
            unified_json = collector.export_to_json(unique_urls, "all_base_model_checkpoints_complete.json")
            unified_txt = collector.export_to_text(unique_urls, "all_base_model_checkpoints_complete.txt")
            
            print(f"çµ±åˆCSV:  {unified_csv}")
            print(f"çµ±åˆJSON: {unified_json}")
            print(f"çµ±åˆTXT:  {unified_txt}")
        
        # æœ€çµ‚çµæœã‚µãƒãƒªãƒ¼
        print(f"\n{'='*60}")
        print(f"ğŸ¯ æœ€çµ‚çµæœã‚µãƒãƒªãƒ¼ï¼ˆå®Œå…¨ç‰ˆï¼‰")
        print(f"{'='*60}")
        
        print(f"{'ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«':<12} {'ä»¥å‰':<8} {'ç¾åœ¨':<8} {'å¢—åŠ æ•°':<8} {'å¢—åŠ ç‡'}")
        print(f"{'-'*55}")
        
        previous_counts = {'pony': 97, 'illustrious': 243, 'noobai': 47}  # ç›´æ¥ã‚¿ã‚°æ¤œç´¢ã®çµæœ
        total_previous = sum(previous_counts.values())
        total_current = 0
        
        for base_model in base_models:
            result = all_results[base_model]
            current = result['count']
            previous = previous_counts[base_model]
            increase = current - previous
            increase_rate = f"{(increase / previous * 100):.1f}%" if previous > 0 else "N/A"
            
            print(f"{base_model:<12} {previous:<8} {current:<8} {increase:<8} {increase_rate}")
            total_current += current
        
        print(f"{'-'*55}")
        total_increase = total_current - total_previous
        total_increase_rate = f"{(total_increase / total_previous * 100):.1f}%"
        print(f"{'åˆè¨ˆ':<12} {total_previous:<8} {total_current:<8} {total_increase:<8} {total_increase_rate}")
        
        # Webãƒšãƒ¼ã‚¸ã¨ã®æ¯”è¼ƒ
        print(f"\nğŸŒ æ¨å®šWebãƒšãƒ¼ã‚¸æ•°ã¨ã®æ¯”è¼ƒ:")
        estimated_web_counts = {'pony': 1000, 'illustrious': 500, 'noobai': 200}  # æ¨å®šå€¤
        for base_model in base_models:
            current = all_results[base_model]['count']
            estimated = estimated_web_counts[base_model]
            coverage = f"{(current / estimated * 100):.1f}%" if estimated > 0 else "N/A"
            print(f"  {base_model}: {current}å€‹ / æ¨å®š{estimated}å€‹ (ã‚«ãƒãƒ¼ç‡: {coverage})")
        
        print(f"\nâœ… å…¨ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®å®Œå…¨å–å¾—ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print(f"å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {collector.output_dir}")
        
    except Exception as e:
        print(f"\nã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()