#!/usr/bin/env python3
"""ä¿®æ­£ã•ã‚ŒãŸAPIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã§å…¨styleã‚¿ã‚°LoRAã‚’å–å¾—ã—ã€ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«åˆ¥ã«åˆ†é¡"""

import os
import sys
from pathlib import Path
from typing import List, Dict, Any

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv
from src.api.client import CivitaiClient
from src.core.url_collector import URLCollector
from src.utils.context_manager import ContextManager


def classify_by_base_model(models: List[Dict], base_model: str) -> List[Dict]:
    """æŒ‡å®šã•ã‚ŒãŸãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã«é–¢é€£ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’åˆ†é¡"""
    filtered = []
    base_model_lower = base_model.lower()
    
    for model in models:
        # ã‚¿ã‚°ã«ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«åãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        tags = model.get('tags', [])
        tag_match = any(base_model_lower in tag.lower() for tag in tags)
        
        # ãƒ¢ãƒ‡ãƒ«åã«ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«åãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        model_name = model.get('name', '')
        name_match = base_model_lower in model_name.lower()
        
        # èª¬æ˜æ–‡ã«ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«åãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        description = model.get('description', '')
        desc_match = base_model_lower in description.lower()
        
        if tag_match or name_match or desc_match:
            filtered.append(model)
    
    return filtered


def main():
    print("=== ä¿®æ­£ç‰ˆï¼šå…¨styleã‚¿ã‚°LoRAå–å¾— & ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«åˆ¥åˆ†é¡ ===")
    
    # ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
    load_dotenv()
    api_key = os.getenv('CIVITAI_API_KEY')
    
    if not api_key:
        print("ã‚¨ãƒ©ãƒ¼: CIVITAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print(".envãƒ•ã‚¡ã‚¤ãƒ«ã§APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        return
    
    try:
        # APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
        print("\n1. Civitai APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–ä¸­...")
        client = CivitaiClient(api_key)
        
        # ä¿®æ­£ã•ã‚ŒãŸAPIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã§å…¨styleã‚¿ã‚°LoRAã‚’å–å¾—
        print("\n2. å…¨styleã‚¿ã‚°LoRAã‚’å–å¾—ä¸­ï¼ˆã‚«ãƒ¼ã‚½ãƒ«ãƒ™ãƒ¼ã‚¹ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ä½¿ç”¨ï¼‰...")
        print("   ã“ã‚Œã«ã¯æ•°åˆ†ã‹ã‹ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™...")
        
        all_style_models = client.search_models_with_cursor(
            types=["LORA"],
            tag="style",
            sort="Highest Rated",
            limit=100,
            max_pages=50  # æœ€å¤§5000å€‹ã¾ã§å–å¾—
        )
        
        print(f"\nâœ… å…¨styleã‚¿ã‚°LoRAå–å¾—å®Œäº†: {len(all_style_models)}å€‹")
        
        # URLåé›†å™¨ã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®åˆæœŸåŒ–
        collector = URLCollector()
        cm = ContextManager()
        
        # ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆ
        base_models = ['pony', 'illustrious', 'noobai']
        base_model_results = {}
        
        print("\n3. ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«åˆ¥ã«åˆ†é¡ä¸­...")
        
        for base_model in base_models:
            print(f"\n--- {base_model.upper()} ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®åˆ†é¡ ---")
            
            # ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã«é–¢é€£ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’åˆ†é¡
            filtered_models = classify_by_base_model(all_style_models, base_model)
            print(f"  {base_model}é–¢é€£: {len(filtered_models)}å€‹")
            
            if filtered_models:
                # URLæƒ…å ±ã‚’åé›†
                urls = collector.collect_model_urls(filtered_models)
                print(f"  ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URL: {len(urls)}å€‹")
                
                # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
                filename_base = f"style_lora_{base_model}_fixed_cursor"
                
                csv_file = collector.export_to_csv(urls, f"{filename_base}.csv")
                json_file = collector.export_to_json(urls, f"{filename_base}.json")
                text_file = collector.export_to_text(urls, f"{filename_base}.txt")
                
                print(f"  ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:")
                print(f"    CSV:  {csv_file}")
                print(f"    JSON: {json_file}")
                print(f"    TXT:  {text_file}")
                
                # çµæœã‚’ä¿å­˜
                base_model_results[base_model] = {
                    'models': filtered_models,
                    'urls': urls,
                    'count': len(filtered_models)
                }
                
                # ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
                print(f"  ğŸ“Š {base_model.upper()}ã‚µãƒ³ãƒ—ãƒ«ï¼ˆä¸Šä½3å€‹ï¼‰:")
                for i, model in enumerate(filtered_models[:3], 1):
                    name = model.get('name', 'Unknown')
                    tags = ', '.join(model.get('tags', [])[:3])
                    print(f"    {i}. {name}")
                    print(f"       ã‚¿ã‚°: {tags}")
                
            else:
                print(f"  âŒ {base_model}é–¢é€£ã®style LoRAãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                base_model_results[base_model] = {'models': [], 'urls': [], 'count': 0}
        
        # çµ±åˆãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ä½œæˆ
        print(f"\n4. çµ±åˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆä¸­...")
        all_urls = collector.collect_model_urls(all_style_models)
        
        unified_csv = collector.export_to_csv(all_urls, "style_lora_all_fixed_cursor.csv")
        unified_json = collector.export_to_json(all_urls, "style_lora_all_fixed_cursor.json")
        unified_txt = collector.export_to_text(all_urls, "style_lora_all_fixed_cursor.txt")
        
        print(f"  çµ±åˆCSV:  {unified_csv}")
        print(f"  çµ±åˆJSON: {unified_json}")
        print(f"  çµ±åˆTXT:  {unified_txt}")
        
        # æœ€çµ‚çµæœã‚µãƒãƒªãƒ¼
        print(f"\n{'='*60}")
        print(f"ğŸ¯ æœ€çµ‚çµæœã‚µãƒãƒªãƒ¼ï¼ˆä¿®æ­£ç‰ˆï¼‰")
        print(f"{'='*60}")
        
        print(f"å…¨styleã‚¿ã‚°LoRAç·æ•°: {len(all_style_models):,}å€‹")
        print(f"")
        print(f"ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«åˆ¥åˆ†é¡:")
        
        total_classified = 0
        for base_model in base_models:
            count = base_model_results[base_model]['count']
            total_classified += count
            print(f"  {base_model.upper():12}: {count:,}å€‹")
        
        unclassified = len(all_style_models) - total_classified
        print(f"  {'ãã®ä»–':>12}: {unclassified:,}å€‹")
        print(f"  {'ç·è¨ˆ':>12}: {len(all_style_models):,}å€‹")
        
        # ä»¥å‰ã®çµæœã¨æ¯”è¼ƒ
        print(f"\nğŸ“ˆ ä»¥å‰ã®çµæœã¨ã®æ¯”è¼ƒ:")
        print(f"  ä»¥å‰: 101å€‹ â†’ ç¾åœ¨: {len(all_style_models):,}å€‹")
        print(f"  æ”¹å–„: {len(all_style_models) - 101:,}å€‹å¢—åŠ  ({((len(all_style_models) - 101) / 101 * 100):.1f}%å‘ä¸Š)")
        
        print(f"\nâœ… å…¨ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®åé›†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print(f"å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {collector.output_dir}")
        
    except Exception as e:
        print(f"\nã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()